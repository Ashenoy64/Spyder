{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4616f699",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31d2a9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(\"page.html\", \"r\", encoding=\"utf-8\") as f:\n",
    "    html = f.read()\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "537467b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "schema = {\n",
    "    \"products\": [\n",
    "        {\n",
    "            \"name\": \"string - Name of the product\",\n",
    "            \"price\": \"string - Price of the product (e.g., â‚¹29,999 or USD 399)\",\n",
    "            \"rating\": \"string or float - Average star rating (e.g., 4.2)\",\n",
    "            \"rating_count\": \"integer - Total number of people who rated the product\",\n",
    "            \"review_count\": \"integer - Number of textual reviews available\",\n",
    "            \"ram\": \"string - RAM details (e.g., 8GB)\",\n",
    "            \"storage\": \"string - Storage details (e.g., 128GB)\",\n",
    "            \"camera\": \"string - Camera specifications (e.g., 50MP dual rear, 16MP front)\",\n",
    "            \"battery\": \"string - Battery details (e.g., 4500mAh with fast charging)\",\n",
    "        }\n",
    "    ]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d87ccfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ollama import chat\n",
    "from ollama import ChatResponse\n",
    "from ollama import Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b71a0c06",
   "metadata": {},
   "outputs": [
    {
     "ename": "ConnectionError",
     "evalue": "Failed to connect to Ollama. Please check that Ollama is downloaded, running and accessible. https://ollama.com/download",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mConnectionError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m client = Client(\n\u001b[32m      2\u001b[39m   host=\u001b[33m'\u001b[39m\u001b[33mhttp://localhost:11434\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m      3\u001b[39m )\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m response = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mqwen2.5:3b\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m  \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mrole\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mWhy is the sky blue?\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m  \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[38;5;28mprint\u001b[39m(response[\u001b[33m'\u001b[39m\u001b[33mmessage\u001b[39m\u001b[33m'\u001b[39m][\u001b[33m'\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# or access fields directly from the response object\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Meowmaster\\Desktop\\PROject\\Spyder\\.venv\\Lib\\site-packages\\ollama\\_client.py:333\u001b[39m, in \u001b[36mClient.chat\u001b[39m\u001b[34m(self, model, messages, tools, stream, format, options, keep_alive)\u001b[39m\n\u001b[32m    289\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mchat\u001b[39m(\n\u001b[32m    290\u001b[39m   \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    291\u001b[39m   model: \u001b[38;5;28mstr\u001b[39m = \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    298\u001b[39m   keep_alive: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mstr\u001b[39m]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    299\u001b[39m ) -> Union[ChatResponse, Iterator[ChatResponse]]:\n\u001b[32m    300\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    301\u001b[39m \u001b[33;03m  Create a chat response using the requested model.\u001b[39;00m\n\u001b[32m    302\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    331\u001b[39m \u001b[33;03m  Returns `ChatResponse` if `stream` is `False`, otherwise returns a `ChatResponse` generator.\u001b[39;00m\n\u001b[32m    332\u001b[39m \u001b[33;03m  \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m333\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    334\u001b[39m \u001b[43m    \u001b[49m\u001b[43mChatResponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    335\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mPOST\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    336\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m/api/chat\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    337\u001b[39m \u001b[43m    \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatRequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    338\u001b[39m \u001b[43m      \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    339\u001b[39m \u001b[43m      \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_copy_messages\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    340\u001b[39m \u001b[43m      \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtool\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtool\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_copy_tools\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtools\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    341\u001b[39m \u001b[43m      \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    342\u001b[39m \u001b[43m      \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    343\u001b[39m \u001b[43m      \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    344\u001b[39m \u001b[43m      \u001b[49m\u001b[43mkeep_alive\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeep_alive\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    345\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodel_dump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexclude_none\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    346\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    347\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Meowmaster\\Desktop\\PROject\\Spyder\\.venv\\Lib\\site-packages\\ollama\\_client.py:178\u001b[39m, in \u001b[36mClient._request\u001b[39m\u001b[34m(self, cls, stream, *args, **kwargs)\u001b[39m\n\u001b[32m    174\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(**part)\n\u001b[32m    176\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m inner()\n\u001b[32m--> \u001b[39m\u001b[32m178\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(**\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request_raw\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m.json())\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Meowmaster\\Desktop\\PROject\\Spyder\\.venv\\Lib\\site-packages\\ollama\\_client.py:124\u001b[39m, in \u001b[36mClient._request_raw\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    122\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m ResponseError(e.response.text, e.response.status_code) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m httpx.ConnectError:\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(CONNECTION_ERROR_MESSAGE) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mConnectionError\u001b[39m: Failed to connect to Ollama. Please check that Ollama is downloaded, running and accessible. https://ollama.com/download"
     ]
    }
   ],
   "source": [
    "client = Client(\n",
    "  host='http://localhost:11434',\n",
    ")\n",
    "\n",
    "response = client.chat(model='qwen2.5:3b', messages=[\n",
    "  {\n",
    "    'role': 'user',\n",
    "    'content': 'Why is the sky blue?',\n",
    "  },\n",
    "])\n",
    "print(response['message']['content'])\n",
    "# or access fields directly from the response object\n",
    "print(response.message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "172da40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_generic_extraction_prompt(schema: dict, soup) -> str:\n",
    "    import json\n",
    "\n",
    "    readable_text = soup.get_text(separator=\"\\n\", strip=True)\n",
    "    limited_text = readable_text[:2500]  # truncate to avoid LLM overload\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "You are an intelligent data extractor.\n",
    "\n",
    "Your task is to extract structured information from a webpage's text content, using the following schema as a guide:\n",
    "\n",
    "Schema:\n",
    "{json.dumps(schema, indent=2)}\n",
    "\n",
    "### Rules:\n",
    "- **Use only the fields defined in the schema.**\n",
    "- If the exact field name is not available, it's acceptable to substitute it with a semantically close or commonly equivalent field (e.g., if \"name\" is missing but \"model\" appears, use \"model\" for \"name\").\n",
    "- **Do not add new fields** that are not part of the schema.\n",
    "- If a field is not present or cannot be confidently extracted, omit it or leave it blank.\n",
    "- Output should be a **valid JSON object** that follows the structure of the schema.\n",
    "- Only include information that appears explicitly in the content.\n",
    "\n",
    "Here is the page content:\n",
    "\\\"\\\"\\\"\n",
    "{limited_text}\n",
    "\\\"\\\"\\\"\n",
    "\n",
    "Now extract and return data that fits the schema above, in JSON format only.\n",
    "\"\"\"\n",
    "\n",
    "    return prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66dc1d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = generate_generic_extraction_prompt(schema, soup)\n",
    "\n",
    "response = client.chat(model='gemma3:4b', messages=[\n",
    "    {\n",
    "        'role': 'user',\n",
    "        'content': prompt,\n",
    "    }\n",
    "])\n",
    "\n",
    "print(response['message']['content'])  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b244f04c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import dotenv\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b5c83ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from groq import Groq\n",
    "client = Groq(api_key=os.environ.get(\"GROQ_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9ce785ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_soup(soup: BeautifulSoup, max_chars: int = 2500) -> str:\n",
    "    \"\"\"\n",
    "    Extract and truncate visible text from a BeautifulSoup object.\n",
    "    \"\"\"\n",
    "    full_text = soup.get_text(separator=\"\\n\", strip=True)\n",
    "    return full_text[:max_chars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8a577872",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_extraction_prompt(schema: dict, page_text: str) -> str:\n",
    "    \"\"\"\n",
    "    Create a prompt for the Groq model to extract structured data using the schema.\n",
    "    \"\"\"\n",
    "    return f\"\"\"\n",
    "Schema:\n",
    "{json.dumps(schema, indent=2)}\n",
    "\n",
    "Here is the page content:\n",
    "\\\"\\\"\\\"\n",
    "{page_text}\n",
    "\\\"\\\"\\\"\n",
    "\n",
    "Your task is to extract structured information from the webpage's text content, using the schema as a guide.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fe809768",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_system_message() -> str:\n",
    "    \"\"\"\n",
    "    Returns the system message that sets the model's behavior.\n",
    "    \"\"\"\n",
    "    return \"\"\"You are an intelligent data extractor.\n",
    "\n",
    "Your task is to extract structured information from a webpage's text content. You have to strictly follow the provided schema as a guide. Sometimes its possible same field might not exist in the page but similar sounding field might exist, in that case you can use that field to fill the data.\n",
    "No need to mention it, you can just use the field that is semantically close or commonly equivalent to the field in the schema. If you feel not all field data exists you can leave the field empty.\n",
    "\n",
    "### Rules:\n",
    "- Use only the fields defined in the schema.\n",
    "- If the exact field name is not available, it's acceptable to substitute it with a semantically close or commonly equivalent field (e.g., if \"name\" is missing but \"model\" appears, use \"model\" for \"name\").\n",
    "- Do not add new fields that are not part of the schema.\n",
    "- If a field is not present or cannot be confidently extracted, omit it or leave it blank.\n",
    "- Output should be a valid JSON object that follows the structure of the schema.\n",
    "- Only include information that appears explicitly in the content.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a97e107d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_structured_data_from_soup(\n",
    "    soup: BeautifulSoup,\n",
    "    schema: dict,\n",
    "    model: str = \"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    max_chars: int = 2500,\n",
    "    show_prompt: bool = False ):\n",
    "    \"\"\"\n",
    "    Full pipeline to generate structured data from HTML soup using a Groq model.\n",
    "    \"\"\"\n",
    "    page_text = extract_text_from_soup(soup, max_chars)\n",
    "    prompt = build_extraction_prompt(schema, page_text)\n",
    "\n",
    "    if show_prompt:\n",
    "        print(\"PROMPT:\\n\", prompt)\n",
    "\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": get_system_message()},\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ],\n",
    "        model=model,\n",
    "    )\n",
    "\n",
    "    return chat_completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4a1f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"llama-3.3-70b-versatile\" # Works\n",
    "model =\"deepseek-r1-distill-llama-70b\" # Works but speaks a lot ( optimal as no limit )\n",
    "model = \"qwen-qwq-32b\" # works but speaks a lot\n",
    "model = \"meta-llama/llama-4-maverick-17b-128e-instruct\" # works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a44e4952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      " \"products\": [\n",
      " {\n",
      " \"name\": \"Nothing Phone (2a)5G (Blue,128 GB)\",\n",
      " \"price\": \"â‚¹19,999\",\n",
      " \"rating\": \"4.4\",\n",
      " \"rating_count\": 97627,\n",
      " \"review_count\": 7907,\n",
      " \"ram\": \"8 GB RAM\",\n",
      " \"storage\": \"128 GB ROM\",\n",
      " \"camera\": \"50MP (OIS) +50MP |32MP Front Camera\",\n",
      " \"battery\": \"5000 mAh Battery\"\n",
      " },\n",
      " {\n",
      " \"name\": \"Nothing Phone (3a) (Black,128 GB)\",\n",
      " \"price\": \"â‚¹24,999\",\n",
      " \"rating\": \"4.5\",\n",
      " \"rating_count\": 20038,\n",
      " \"review_count\": 1928,\n",
      " \"ram\": \"8 GB RAM\",\n",
      " \"storage\": \"128 GB ROM\",\n",
      " \"camera\": \"50MP (Main) +50MP (2X Tele Photo) +8MP (Ultra-Wide) |32MP Front Camera\",\n",
      " \"battery\": \"5000 mAh Battery\"\n",
      " },\n",
      " {\n",
      " \"name\": \"Nothing Phone (3a) (White,256 GB)\",\n",
      " \"price\": \"\",\n",
      " \"rating\": \"4.5\",\n",
      " \"rating_count\": 20038,\n",
      " \"review_count\": 1928,\n",
      " \"ram\": \"8 GB RAM\",\n",
      " \"storage\": \"256 GB ROM\",\n",
      " \"camera\": \"50MP (Main) +50MP (2X Tele Photo) +8MP (Ultra-Wide) |32MP Front Camera\",\n",
      " \"battery\": \"5000 mAh Battery\"\n",
      " }\n",
      " ]\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "result_json = extract_structured_data_from_soup(soup, schema, model=\"meta-llama/llama-4-maverick-17b-128e-instruct\")\n",
    "print(result_json)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
